triton_models:
    general_ocr:
        model_spec_name: general_ocr
        model_spec_version: 72024010301003
        input_shape: [40, 416, 3]
        input_name: input
        input_type: FP32
        output_name: output
        charset: "0123456789!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzÀÁẢÃẠĂẰẮẲẴẶÂẦẤẨẪẬĐÈÉẺẼẸÊỀẾỂỄỆÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴàáảãạăằắẳẵặâầấẩẫậđèéẻẽẹêềếểễệìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵ"
        max_batch_size: 8
        request_timeout: 60.0


    text_detection:
        model_spec_name: text_detection
        model_spec_version: 72024041501004
        input_name: input
        input_type: UINT8
        output_name: output
        box_thresh: 0.5
        p_thresh: 0.3
        unclip_ratio: 1.6
        request_timeout: 60.0


    receipt_information_extraction:
        model_spec_name: information_extraction
        model_spec_version: 72024041501004
        input_name: [input_ids, bbox, attention_mask, pixel_values]
        input_type: [INT64, INT64, INT64, FP32]
        output_name: output
        model_dir: models_receipt
        request_timeout: 60.0


vllm_models:
    base-model:
        base_model_name: Qwen2.5-1.5B-Instruct
        lora_name: /models/Qwen2.5-1.5B-Instruct
        max_tokens: 8192
        temperature: 0
        top_p: 1
    receipt-lora:
        base_model_name: Qwen2.5-1.5B-Instruct
        lora_name: receipt-lora
        max_tokens: 10144
        temperature: 0
        top_p: 1